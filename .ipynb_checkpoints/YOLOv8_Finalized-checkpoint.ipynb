{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c35b324",
   "metadata": {},
   "source": [
    "# Importing Libreries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efeca5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "from twilio.rest import Client\n",
    "# account_sid = 'ACbac462ab71411eb8a4d32fc5686251fa'\n",
    "# auth_token = '[AuthToken]'\n",
    "# client = Client(account_sid, auth_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21201c3",
   "metadata": {},
   "source": [
    "# Load, Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c213e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n classification model\n",
    "# model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
    "# model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104459ed",
   "metadata": {},
   "source": [
    "# Enable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ecc792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58054654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba9e125f",
   "metadata": {},
   "source": [
    "# YOLO Fall Detection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219e12ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 210.4ms\n",
      "Speed: 5.0ms preprocess, 210.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 231.4ms\n",
      "Speed: 7.0ms preprocess, 231.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 198.0ms\n",
      "Speed: 5.0ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 207.0ms\n",
      "Speed: 5.0ms preprocess, 207.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 226.0ms\n",
      "Speed: 9.0ms preprocess, 226.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 199.9ms\n",
      "Speed: 5.0ms preprocess, 199.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 227.9ms\n",
      "Speed: 5.0ms preprocess, 227.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 (no detections), 179.9ms\n",
      "Speed: 4.0ms preprocess, 179.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 180.9ms\n",
      "Speed: 4.0ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 190.9ms\n",
      "Speed: 5.0ms preprocess, 190.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 2 persons, 171.1ms\n",
      "Speed: 6.0ms preprocess, 171.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n",
      "Speed: 5.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 194.0ms\n",
      "Speed: 3.0ms preprocess, 194.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 224.0ms\n",
      "Speed: 6.0ms preprocess, 224.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.0ms\n",
      "Speed: 3.5ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 201.0ms\n",
      "Speed: 3.0ms preprocess, 201.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 148.0ms\n",
      "Speed: 6.0ms preprocess, 148.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 188.9ms\n",
      "Speed: 3.0ms preprocess, 188.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 179.1ms\n",
      "Speed: 7.0ms preprocess, 179.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 196.5ms\n",
      "Speed: 21.0ms preprocess, 196.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 162.9ms\n",
      "Speed: 3.1ms preprocess, 162.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 207.0ms\n",
      "Speed: 3.0ms preprocess, 207.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 171.1ms\n",
      "Speed: 4.0ms preprocess, 171.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 10.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 171.0ms\n",
      "Speed: 3.0ms preprocess, 171.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 179.0ms\n",
      "Speed: 6.0ms preprocess, 179.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 164.0ms\n",
      "Speed: 8.1ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 156.9ms\n",
      "Speed: 3.0ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 156.0ms\n",
      "Speed: 5.5ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 156.0ms\n",
      "Speed: 4.0ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 155.0ms\n",
      "Speed: 5.0ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 161.0ms\n",
      "Speed: 8.0ms preprocess, 161.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 6.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 4.0ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 157.0ms\n",
      "Speed: 3.0ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 165.0ms\n",
      "Speed: 3.0ms preprocess, 165.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 212.0ms\n",
      "Speed: 3.0ms preprocess, 212.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 160.0ms\n",
      "Speed: 4.0ms preprocess, 160.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 154.0ms\n",
      "Speed: 4.0ms preprocess, 154.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 159.5ms\n",
      "Speed: 5.5ms preprocess, 159.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 164.0ms\n",
      "Speed: 4.0ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n",
      "Speed: 3.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n",
      "Speed: 4.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 177.1ms\n",
      "Speed: 3.0ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n",
      "Speed: 4.0ms preprocess, 162.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 167.0ms\n",
      "Speed: 4.1ms preprocess, 167.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 160.0ms\n",
      "Speed: 4.0ms preprocess, 160.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 163.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 3.0ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 165.0ms\n",
      "Speed: 3.0ms preprocess, 165.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 236.0ms\n",
      "Speed: 3.0ms preprocess, 236.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 234.0ms\n",
      "Speed: 4.0ms preprocess, 234.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 222.0ms\n",
      "Speed: 7.0ms preprocess, 222.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 218.0ms\n",
      "Speed: 3.0ms preprocess, 218.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 252.0ms\n",
      "Speed: 4.0ms preprocess, 252.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 243.0ms\n",
      "Speed: 5.0ms preprocess, 243.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 241.0ms\n",
      "Speed: 4.0ms preprocess, 241.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 255.9ms\n",
      "Speed: 5.1ms preprocess, 255.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 246.0ms\n",
      "Speed: 4.0ms preprocess, 246.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 249.0ms\n",
      "Speed: 4.0ms preprocess, 249.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 238.0ms\n",
      "Speed: 4.0ms preprocess, 238.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 258.0ms\n",
      "Speed: 4.0ms preprocess, 258.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 264.1ms\n",
      "Speed: 6.0ms preprocess, 264.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 254.9ms\n",
      "Speed: 7.0ms preprocess, 254.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 253.0ms\n",
      "Speed: 5.0ms preprocess, 253.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 207.0ms\n",
      "Speed: 5.0ms preprocess, 207.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 6.0ms preprocess, 168.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 167.0ms\n",
      "Speed: 4.0ms preprocess, 167.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 174.0ms\n",
      "Speed: 4.0ms preprocess, 174.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 196.0ms\n",
      "Speed: 5.0ms preprocess, 196.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 193.0ms\n",
      "Speed: 4.0ms preprocess, 193.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 3.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 4.0ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 178.0ms\n",
      "Speed: 3.5ms preprocess, 178.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 177.0ms\n",
      "Speed: 3.0ms preprocess, 177.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 204.0ms\n",
      "Speed: 15.0ms preprocess, 204.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.5ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 152.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 151.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.1ms preprocess, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 173.0ms\n",
      "Speed: 3.0ms preprocess, 173.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 4.5ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 170.0ms\n",
      "Speed: 3.0ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 156.8ms\n",
      "Speed: 5.0ms preprocess, 156.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 161.5ms\n",
      "Speed: 3.5ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 168.0ms\n",
      "Speed: 3.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 152.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 9.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 156.0ms\n",
      "Speed: 5.0ms preprocess, 156.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 150.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 150.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 159.0ms\n",
      "Speed: 3.0ms preprocess, 159.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 3.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 152.0ms\n",
      "Speed: 5.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 154.0ms\n",
      "Speed: 3.0ms preprocess, 154.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 162.0ms\n",
      "Speed: 5.0ms preprocess, 162.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 162.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 3.0ms preprocess, 162.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 159.5ms\n",
      "Speed: 3.5ms preprocess, 159.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 146.9ms\n",
      "Speed: 4.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n",
      "\n",
      "0: 480x640 1 person, 150.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 5.0ms preprocess, 150.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict16\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall detected!\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------pose estimation model---------------------------------------------\n",
    "# Define the video capture device\n",
    "\n",
    "# cap = cv2.VideoCapture(\"video (2).avi\")\n",
    "source =\"video (1).avi\" \n",
    "# source =\"sleep.mp4\" \n",
    "cap = cv2.VideoCapture(source)\n",
    "mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "\n",
    "\n",
    "#------------------------Saving the output to the server side--------------------------------------------\n",
    "#----the incoder-------\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#----------------------------------------\n",
    "#--------encoding the output streams--------\n",
    "# THE public video with privacy..\n",
    "result_Public = cv2.VideoWriter('C:\\\\Users\\\\kools\\\\Downloads\\\\Grad\\\\YOLO V8\\\\OUT\\\\public_skelton.mp4', fourcc, 10, (640,480))\n",
    "# THE private video\n",
    "result_private = cv2.VideoWriter('C:\\\\Users\\\\kools\\\\Downloads\\\\Grad\\\\YOLO V8\\\\OUT\\\\private_RGB.mp4', fourcc, 10, (640,480))\n",
    "#---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#----------------------\n",
    "fall_counter = 0\n",
    "#----------------------\n",
    "\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    # Read a frame from the video stream\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame,(640,480))\n",
    "\n",
    "    \n",
    "    # Stop the program if no frame is read\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Use the model to predict the poses in the frame\n",
    "    results = model.predict(frame,save=True)\n",
    "    detections = results[0].plot()\n",
    "\n",
    "\n",
    "    #-------------------------------------MOG-----------------------------\n",
    "    #     grey = cv2.copyTo(grayImage,frame)\n",
    "    mog_first = mog2.apply(frame)\n",
    "    #     cv.imshow('frame',fgmask)\n",
    "    #------------------------------------------------\n",
    "\n",
    "    #----------other methods similar to mog----------\n",
    " \n",
    "    mog_detections0 = cv2.copyTo(frame,mog_first)\n",
    "    #     denoised_2 = cv2.blur(mog_detections0, (15, 15))\n",
    "    #     grayImage = cv2.cvtColor(mog_detections0, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, blackAndWhiteFrame) = cv2.threshold(grayFrame, 70, 255, cv2.THRESH_BINARY)\n",
    "    #------------------------------------------------------------------------\n",
    "  \n",
    "    \n",
    "\n",
    "    #-----------------retrieving skelaton from YOLO--------------------------\n",
    "    boxes = results[0].boxes\n",
    "    #converting the images torch output from yolo to list\n",
    "    torch_to_list = boxes.xywh.tolist()\n",
    "\n",
    "    #cdiminsion of the torch array \n",
    "    a = array(torch_to_list)\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # Create a copy of the frame without the boundary boxes\n",
    "    frame_copy = frame.copy()\n",
    "    #------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------DETECTING FALLS------------------------------------\n",
    "    # If the distance to the ground is below a threshold, then the person has fallen\n",
    "    if  a.shape == (1,4):\n",
    "        distance_to_ground = torch_to_list[0][3] #Getting The Hight of boundry box\n",
    "        keypoints_width = torch_to_list[0][2] ##Getting The width of boundry box\n",
    "        \n",
    "        #-----------handling sleeping case-----------------------------\n",
    "        if distance_to_ground < keypoints_width and source !=\"sleep.mp4\" :\n",
    "\n",
    "            print(\"Fall detected!\")\n",
    "            fall_counter = fall_counter + 1\n",
    "\n",
    "    #----------------------------messaging send, Request--------------------------------\n",
    "#             if fall_counter == 5:\n",
    "#                 client.messages.create(body = \"Fall Detected, Please check your Application..\",from_ = '+13855262860', to='+201014454866')\n",
    "\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    #----------------------------if the person is not sleeping-----------------------------\n",
    "            for r in results:\n",
    "                annotator = Annotator(frame)\n",
    "\n",
    "                boxes = r.boxes\n",
    "                for box in boxes:\n",
    "                        b = box.xyxy[0]  # top, left, bottom, right) format\n",
    "                        c = box.cls\n",
    "                        annotator.box_label(b, \"Fall Detected\")\n",
    "\n",
    "                frame = annotator.result()  \n",
    "\n",
    "\n",
    "        else:\n",
    "            for r in results:\n",
    "                annotator = Annotator(frame)\n",
    "\n",
    "                boxes = r.boxes\n",
    "                for box in boxes:\n",
    "                        b = box.xyxy[0]  #(top, left, bottom, right) format\n",
    "                        c = box.cls\n",
    "                        annotator.box_label(b, \"Normal\")\n",
    "\n",
    "                frame = annotator.result()  \n",
    "    #---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------output_streams--------------------------------------\n",
    "    #--------------------------cashing---------------------\n",
    "    #sending the image to the cache to prevent np problem \n",
    "    cv2.imwrite('C:\\\\Users\\\\kools\\\\Downloads\\\\Grad\\\\YOLO V8\\\\Cache\\\\temp.jpg', blackAndWhiteFrame)\n",
    "    public_stream = cv2.imread('C:\\\\Users\\\\kools\\\\Downloads\\\\Grad\\\\YOLO V8\\\\Cache\\\\temp.jpg')\n",
    "\n",
    "    \n",
    "    #------------------------------------------------------\n",
    "    #sending the output video to the app\n",
    " \n",
    "    result_Public.write(public_stream) \n",
    "    result_private.write(frame_copy)\n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    cv2.imshow('Pose estimation Fall Detection', frame)\n",
    "    cv2.imshow('skeleton ', detections)\n",
    "    cv2.imshow('MOG ', blackAndWhiteFrame)\n",
    "\n",
    "    # Exit the program if the user presses the 'q' key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture device and close the display window\n",
    "result_Public.release()\n",
    "result_private.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372d745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
